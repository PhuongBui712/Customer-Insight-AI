{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.utils import *\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "from src.prompt import extract_keyword_prompt, important_inquiry_prompt\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n",
    "\n",
    "In this step, we will apply 2 methods to extract insightful data from customer's message:\n",
    "- **Extracting keyword**: Use LLM to distil important keywords in messages\n",
    "- **Meaningful inquiries**: Use LLM to detect any important, insightful customer's inquiries about products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = load_json('../data/customer_messages.json')\n",
    "message_list = [m['message'] for m in customer_messages]\n",
    "# load small sample to test\n",
    "SAMPLE_SIZE = 50\n",
    "small_sample = message_list[:SAMPLE_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD LLM**\n",
    "\n",
    "We will use ***Gemini-1.5-flash*** of Google, which is one of the state of the art LLMs (or even Multimodal model) in the present. Furthermore, this model is also provided a good API capacity for free tier.\n",
    "\n",
    "Because of requirement of precision and static output, we also need to modify `temperature`, `top_p`, and `top_k` to ensure model work accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.1, top_k=10, top_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(s: str) -> list:\n",
    "    start = s.index('[')\n",
    "    end =  -s[::-1].index(']')\n",
    "    try:\n",
    "        res = json.loads(s[start:end])\n",
    "    except Exception:\n",
    "        raise Exception(f\"Could not parse output. Expected output in either '```python' or '```json' format. Received: {s}\")\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keywords_chain = extract_keyword_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em xin menu sÃºp bÃªn mÃ¬nh vá»›i áº¡ -> ['sÃºp', 'menu']\n",
      "xin menu -> ['menu']\n",
      "XEM MENU -> ['menu']\n",
      "XIN MENU -> ['menu']\n",
      "e xin menu áº¡ -> ['menu']\n",
      "XIN MENU -> ['menu']\n",
      "Em xin menu áº¡ -> ['menu']\n",
      "Loáº¡i tiá»ƒu báº£o gá»“m cÃ³ thÃ nh pháº§n gÃ¬ áº¡ -> ['tiá»ƒu báº£o', 'thÃ nh pháº§n']\n",
      "BÃ¬nh long tÃ¢n phÃº nháº­n ká»‹p 4h30 ko áº¡ -> ['bÃ¬nh long tÃ¢n phÃº', 'váº­n chuyá»ƒn']\n",
      "196k pk áº¡ -> ['giÃ¡ cáº£']\n",
      "Ká»‹p ko áº¡ -> ['váº­n chuyá»ƒn']\n",
      "Táº¡i em lÃ m á»Ÿ cty 4h30 em ra ca vá» rá»“i áº¡ -> ['váº­n chuyá»ƒn']\n",
      "Váº­y canh sao giao tá»›i Ä‘Ã¢y 4h30 dÃ¹m em nha -> ['váº­n chuyá»ƒn']\n",
      "Táº¡i 4h30 em má»›i ra ca -> ['váº­n chuyá»ƒn']\n",
      "32 bÃ¬nh long quáº­n tÃ¢n phÃº\n",
      "0377428748 -> ['bÃ¬nh long', 'tÃ¢n phÃº']\n",
      "Ko áº¡ -> ['váº­n chuyá»ƒn']\n",
      "Ship sao tá»›i Ä‘Ã¢y 4h 30 dÃ¹m em nha -> ['váº­n chuyá»ƒn']\n",
      "Sá»›m quÃ¡ em ko nháº­n Ä‘c -> ['váº­n chuyá»ƒn']\n",
      "ÄÆ¡n hÃ ng cá»§a em Ä‘i chÆ°a áº¡ -> ['Ä‘Æ¡n hÃ ng']\n",
      "Ok shop -> []\n",
      "KhÃ´ng áº¡ , em ráº¥t hÃ i lÃ²ng vá» mÃ³n Äƒn vÃ  cÃ¡ch Ä‘Ã³ng gÃ³i áº¡ ðŸ¥° -> []\n",
      "VÃ¢ng áº¡ em nháº­n Ä‘á»§ -> []\n",
      "VÃ¢ng áº¡ láº§n sau em sáº½ á»§ng há»™ tiáº¿p mÃ³n khÃ¡c áº¡ -> []\n",
      "thÃ nh pháº§n gá»“m nhá»¯ng gÃ¬? -> ['thÃ nh pháº§n']\n",
      "xin menu -> ['menu']\n",
      "Hi -> []\n",
      "Cho chá»‹ xem menu -> ['menu']\n",
      "Ship chá»‹ 1 pháº§n 290k nha -> ['váº­n chuyá»ƒn', 'giÃ¡ cáº£']\n",
      "Bá»‡nh viá»‡n hoÃ ng anh gia lai -> ['bá»‡nh viá»‡n hoÃ ng anh gia lai']\n",
      "Ship lÃªn táº§ng 5 nha -> ['váº­n chuyá»ƒn']\n",
      "Táº§ng 5 bá»‡nh viá»‡n hoÃ ng anh gia lai -> ['bá»‡nh viá»‡n hoÃ ng anh gia lai', 'váº­n chuyá»ƒn']\n",
      "0905079060 -> []\n",
      "Ko -> ['váº­n chuyá»ƒn']\n",
      "Ship nhanh nha -> ['sÃºp bÃ o ngÆ° tÄƒng lá»±c', 'gia Ä‘Ã¬nh', 'ngÆ°á»i thÃ¢n', 'Ä‘á»‘i tÃ¡c']\n",
      "Äáº·t SÃºp BÃ o NgÆ° TÄ‚NG Lá»°C cho Gia ÄÃ¬nh / NgÆ°á»i ThÃ¢n / Äá»‘i TÃ¡c -> ['sÃºp bÃ o ngÆ° tÄƒng lá»±c', '1 ngÆ°á»i']\n",
      "1 ngÆ°á»i Äƒn áº¡ -> ['sÃºp bÃ o ngÆ° tÄƒng lá»±c', 'á»‘m']\n",
      "Bá»‹ á»‘m áº¡ -> ['sÃºp bÃ o ngÆ° tÄƒng lá»±c', 'gia Ä‘Ã¬nh', 'ngÆ°á»i thÃ¢n', 'Ä‘á»‘i tÃ¡c']\n",
      "Äáº·t SÃºp BÃ o NgÆ° TÄ‚NG Lá»°C cho Gia ÄÃ¬nh / NgÆ°á»i ThÃ¢n / Äá»‘i TÃ¡c -> ['menu']\n",
      "XIN MENU -> ['menu']\n",
      "xin menu -> ['sÃºp bÃ o ngÆ°', 'thÄƒm ngÆ°á»i á»‘m']\n",
      "Äáº·t SÃºp BÃ o NgÆ° thÄƒm ngÆ°á»i á»m! -> ['sÃºp bÃ o ngÆ°', 'ngÆ°á»i nhÃ ', 'bá»‡nh']\n",
      "Mua cho  ngÆ°á»i nhÃ   bá»‹  bá»‡nh Äƒn -> ['menu']\n",
      "xin menu -> []\n",
      "CÃ³ ai chat khÃ´ng áº¡ -> ['sÃºp', 'Ä‘áº·t']\n",
      "Minh muá»‘n Ä‘áº·t dÃ¹ng áº¥y áº¡ -> ['thiá»‡p']\n",
      "ko kÃ¨m thiá»‡p -> ['sÃºp tiá»ƒu báº£o', 'Ä‘áº·t']\n",
      "Minh muá»‘n Ä‘áº·t 1 pháº§n sÃºp Tiá»ƒu Báº£o. -> ['váº­n chuyá»ƒn']\n",
      "Táº§m 18h cÃ²n ship k áº¡ -> []\n",
      "SDT: 0815.862.226\n",
      "Äá»‹a chá»‰: LÃ´ NP2-13, NP2-19 khu Trung tÃ¢m thÆ°Æ¡ng máº¡i Äáº¡i siÃªu thá»‹ BigC, P. ÄÃ´ng Háº£i, TP. Thanh HÃ³a (Báº£o hiá»ƒm Agribank). -> ['váº­n chuyá»ƒn']\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords_chain.invoke({'input': str(small_sample)})\n",
    "keywords = parse_output(keywords)\n",
    "for mess, keyword_list in zip(small_sample, keywords):\n",
    "    print(f'{mess} -> {keyword_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Inquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_inquiry_chain = important_inquiry_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_message_mask = important_inquiry_chain.invoke({'input': str(small_sample)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em xin menu sÃºp bÃªn mÃ¬nh vá»›i áº¡ -> False\n",
      "xin menu -> False\n",
      "XEM MENU -> False\n",
      "XIN MENU -> False\n",
      "e xin menu áº¡ -> False\n",
      "XIN MENU -> False\n",
      "Em xin menu áº¡ -> False\n",
      "Loáº¡i tiá»ƒu báº£o gá»“m cÃ³ thÃ nh pháº§n gÃ¬ áº¡ -> True\n",
      "BÃ¬nh long tÃ¢n phÃº nháº­n ká»‹p 4h30 ko áº¡ -> False\n",
      "196k pk áº¡ -> False\n",
      "Ká»‹p ko áº¡ -> False\n",
      "Táº¡i em lÃ m á»Ÿ cty 4h30 em ra ca vá» rá»“i áº¡ -> False\n",
      "Váº­y canh sao giao tá»›i Ä‘Ã¢y 4h30 dÃ¹m em nha -> False\n",
      "Táº¡i 4h30 em má»›i ra ca -> False\n",
      "32 bÃ¬nh long quáº­n tÃ¢n phÃº\n",
      "0377428748 -> False\n",
      "Ko áº¡ -> False\n",
      "Ship sao tá»›i Ä‘Ã¢y 4h 30 dÃ¹m em nha -> False\n",
      "Sá»›m quÃ¡ em ko nháº­n Ä‘c -> False\n",
      "ÄÆ¡n hÃ ng cá»§a em Ä‘i chÆ°a áº¡ -> False\n",
      "Ok shop -> False\n",
      "KhÃ´ng áº¡ , em ráº¥t hÃ i lÃ²ng vá» mÃ³n Äƒn vÃ  cÃ¡ch Ä‘Ã³ng gÃ³i áº¡ ðŸ¥° -> True\n",
      "VÃ¢ng áº¡ em nháº­n Ä‘á»§ -> True\n",
      "VÃ¢ng áº¡ láº§n sau em sáº½ á»§ng há»™ tiáº¿p mÃ³n khÃ¡c áº¡ -> True\n",
      "thÃ nh pháº§n gá»“m nhá»¯ng gÃ¬? -> False\n",
      "xin menu -> False\n",
      "Hi -> False\n",
      "Cho chá»‹ xem menu -> False\n",
      "Ship chá»‹ 1 pháº§n 290k nha -> False\n",
      "Bá»‡nh viá»‡n hoÃ ng anh gia lai -> False\n",
      "Ship lÃªn táº§ng 5 nha -> False\n",
      "Táº§ng 5 bá»‡nh viá»‡n hoÃ ng anh gia lai -> False\n",
      "0905079060 -> False\n",
      "Ko -> False\n",
      "Ship nhanh nha -> False\n",
      "Äáº·t SÃºp BÃ o NgÆ° TÄ‚NG Lá»°C cho Gia ÄÃ¬nh / NgÆ°á»i ThÃ¢n / Äá»‘i TÃ¡c -> False\n",
      "1 ngÆ°á»i Äƒn áº¡ -> True\n",
      "Bá»‹ á»‘m áº¡ -> True\n",
      "Äáº·t SÃºp BÃ o NgÆ° TÄ‚NG Lá»°C cho Gia ÄÃ¬nh / NgÆ°á»i ThÃ¢n / Äá»‘i TÃ¡c -> True\n",
      "XIN MENU -> False\n",
      "xin menu -> False\n",
      "Äáº·t SÃºp BÃ o NgÆ° thÄƒm ngÆ°á»i á»m! -> False\n",
      "Mua cho  ngÆ°á»i nhÃ   bá»‹  bá»‡nh Äƒn -> True\n",
      "xin menu -> False\n",
      "CÃ³ ai chat khÃ´ng áº¡ -> False\n",
      "Minh muá»‘n Ä‘áº·t dÃ¹ng áº¥y áº¡ -> True\n",
      "ko kÃ¨m thiá»‡p -> False\n",
      "Minh muá»‘n Ä‘áº·t 1 pháº§n sÃºp Tiá»ƒu Báº£o. -> False\n"
     ]
    }
   ],
   "source": [
    "important_message_mask = parse_output(important_message_mask)\n",
    "for mess, flag in zip(small_sample, important_message_mask):\n",
    "    print(f'{mess} -> {flag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
