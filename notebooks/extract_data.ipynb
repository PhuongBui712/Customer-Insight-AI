{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.utils import *\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "from src.prompt import extract_keyword_prompt, important_inquiry_prompt\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n",
    "\n",
    "In this step, we will apply 2 methods to extract insightful data from customer's message:\n",
    "- **Extracting keyword**: Use LLM to distil important keywords in messages\n",
    "- **Meaningful inquiries**: Use LLM to detect any important, insightful customer's inquiries about products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = load_json('../data/customer_messages.json')\n",
    "message_list = [m['message'] for m in customer_messages]\n",
    "# load small sample to test\n",
    "SAMPLE_SIZE = 50\n",
    "small_sample = message_list[:SAMPLE_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD LLM**\n",
    "\n",
    "We will use ***Gemini-1.5-flash*** of Google, which is one of the state of the art LLMs (or even Multimodal model) in the present. Furthermore, this model is also provided a good API capacity for free tier.\n",
    "\n",
    "Because of requirement of precision and static output, we also need to modify `temperature`, `top_p`, and `top_k` to ensure model work accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.1, top_k=10, top_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(s: str) -> list:\n",
    "    start = s.index('[')\n",
    "    end =  -s[::-1].index(']')\n",
    "    try:\n",
    "        res = json.loads(s[start:end])\n",
    "    except Exception:\n",
    "        raise Exception(f\"Could not parse output. Expected output in either '```python' or '```json' format. Received: {s}\")\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keywords_chain = extract_keyword_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em xin menu súp bên mình với ạ -> ['súp', 'menu']\n",
      "xin menu -> ['menu']\n",
      "XEM MENU -> ['menu']\n",
      "XIN MENU -> ['menu']\n",
      "e xin menu ạ -> ['menu']\n",
      "XIN MENU -> ['menu']\n",
      "Em xin menu ạ -> ['menu']\n",
      "Loại tiểu bảo gồm có thành phần gì ạ -> ['tiểu bảo', 'thành phần']\n",
      "Bình long tân phú nhận kịp 4h30 ko ạ -> ['bình long tân phú', 'vận chuyển']\n",
      "196k pk ạ -> ['giá cả']\n",
      "Kịp ko ạ -> ['vận chuyển']\n",
      "Tại em làm ở cty 4h30 em ra ca về rồi ạ -> ['vận chuyển']\n",
      "Vậy canh sao giao tới đây 4h30 dùm em nha -> ['vận chuyển']\n",
      "Tại 4h30 em mới ra ca -> ['vận chuyển']\n",
      "32 bình long quận tân phú\n",
      "0377428748 -> ['bình long', 'tân phú']\n",
      "Ko ạ -> ['vận chuyển']\n",
      "Ship sao tới đây 4h 30 dùm em nha -> ['vận chuyển']\n",
      "Sớm quá em ko nhận đc -> ['vận chuyển']\n",
      "Đơn hàng của em đi chưa ạ -> ['đơn hàng']\n",
      "Ok shop -> []\n",
      "Không ạ , em rất hài lòng về món ăn và cách đóng gói ạ 🥰 -> []\n",
      "Vâng ạ em nhận đủ -> []\n",
      "Vâng ạ lần sau em sẽ ủng hộ tiếp món khác ạ -> []\n",
      "thành phần gồm những gì? -> ['thành phần']\n",
      "xin menu -> ['menu']\n",
      "Hi -> []\n",
      "Cho chị xem menu -> ['menu']\n",
      "Ship chị 1 phần 290k nha -> ['vận chuyển', 'giá cả']\n",
      "Bệnh viện hoàng anh gia lai -> ['bệnh viện hoàng anh gia lai']\n",
      "Ship lên tầng 5 nha -> ['vận chuyển']\n",
      "Tầng 5 bệnh viện hoàng anh gia lai -> ['bệnh viện hoàng anh gia lai', 'vận chuyển']\n",
      "0905079060 -> []\n",
      "Ko -> ['vận chuyển']\n",
      "Ship nhanh nha -> ['súp bào ngư tăng lực', 'gia đình', 'người thân', 'đối tác']\n",
      "Đặt Súp Bào Ngư TĂNG LỰC cho Gia Đình / Người Thân / Đối Tác -> ['súp bào ngư tăng lực', '1 người']\n",
      "1 người ăn ạ -> ['súp bào ngư tăng lực', 'ốm']\n",
      "Bị ốm ạ -> ['súp bào ngư tăng lực', 'gia đình', 'người thân', 'đối tác']\n",
      "Đặt Súp Bào Ngư TĂNG LỰC cho Gia Đình / Người Thân / Đối Tác -> ['menu']\n",
      "XIN MENU -> ['menu']\n",
      "xin menu -> ['súp bào ngư', 'thăm người ốm']\n",
      "Đặt Súp Bào Ngư thăm người Ốm! -> ['súp bào ngư', 'người nhà', 'bệnh']\n",
      "Mua cho  người nhà  bị  bệnh ăn -> ['menu']\n",
      "xin menu -> []\n",
      "Có ai chat không ạ -> ['súp', 'đặt']\n",
      "Minh muốn đặt dùng ấy ạ -> ['thiệp']\n",
      "ko kèm thiệp -> ['súp tiểu bảo', 'đặt']\n",
      "Minh muốn đặt 1 phần súp Tiểu Bảo. -> ['vận chuyển']\n",
      "Tầm 18h còn ship k ạ -> []\n",
      "SDT: 0815.862.226\n",
      "Địa chỉ: Lô NP2-13, NP2-19 khu Trung tâm thương mại Đại siêu thị BigC, P. Đông Hải, TP. Thanh Hóa (Bảo hiểm Agribank). -> ['vận chuyển']\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords_chain.invoke({'input': str(small_sample)})\n",
    "keywords = parse_output(keywords)\n",
    "for mess, keyword_list in zip(small_sample, keywords):\n",
    "    print(f'{mess} -> {keyword_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Inquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_inquiry_chain = important_inquiry_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_message_mask = important_inquiry_chain.invoke({'input': str(small_sample)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em xin menu súp bên mình với ạ -> False\n",
      "xin menu -> False\n",
      "XEM MENU -> False\n",
      "XIN MENU -> False\n",
      "e xin menu ạ -> False\n",
      "XIN MENU -> False\n",
      "Em xin menu ạ -> False\n",
      "Loại tiểu bảo gồm có thành phần gì ạ -> True\n",
      "Bình long tân phú nhận kịp 4h30 ko ạ -> False\n",
      "196k pk ạ -> False\n",
      "Kịp ko ạ -> False\n",
      "Tại em làm ở cty 4h30 em ra ca về rồi ạ -> False\n",
      "Vậy canh sao giao tới đây 4h30 dùm em nha -> False\n",
      "Tại 4h30 em mới ra ca -> False\n",
      "32 bình long quận tân phú\n",
      "0377428748 -> False\n",
      "Ko ạ -> False\n",
      "Ship sao tới đây 4h 30 dùm em nha -> False\n",
      "Sớm quá em ko nhận đc -> False\n",
      "Đơn hàng của em đi chưa ạ -> False\n",
      "Ok shop -> False\n",
      "Không ạ , em rất hài lòng về món ăn và cách đóng gói ạ 🥰 -> True\n",
      "Vâng ạ em nhận đủ -> True\n",
      "Vâng ạ lần sau em sẽ ủng hộ tiếp món khác ạ -> True\n",
      "thành phần gồm những gì? -> False\n",
      "xin menu -> False\n",
      "Hi -> False\n",
      "Cho chị xem menu -> False\n",
      "Ship chị 1 phần 290k nha -> False\n",
      "Bệnh viện hoàng anh gia lai -> False\n",
      "Ship lên tầng 5 nha -> False\n",
      "Tầng 5 bệnh viện hoàng anh gia lai -> False\n",
      "0905079060 -> False\n",
      "Ko -> False\n",
      "Ship nhanh nha -> False\n",
      "Đặt Súp Bào Ngư TĂNG LỰC cho Gia Đình / Người Thân / Đối Tác -> False\n",
      "1 người ăn ạ -> True\n",
      "Bị ốm ạ -> True\n",
      "Đặt Súp Bào Ngư TĂNG LỰC cho Gia Đình / Người Thân / Đối Tác -> True\n",
      "XIN MENU -> False\n",
      "xin menu -> False\n",
      "Đặt Súp Bào Ngư thăm người Ốm! -> False\n",
      "Mua cho  người nhà  bị  bệnh ăn -> True\n",
      "xin menu -> False\n",
      "Có ai chat không ạ -> False\n",
      "Minh muốn đặt dùng ấy ạ -> True\n",
      "ko kèm thiệp -> False\n",
      "Minh muốn đặt 1 phần súp Tiểu Bảo. -> False\n"
     ]
    }
   ],
   "source": [
    "important_message_mask = parse_output(important_message_mask)\n",
    "for mess, flag in zip(small_sample, important_message_mask):\n",
    "    print(f'{mess} -> {flag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
